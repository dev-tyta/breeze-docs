# Bree-MD Documentation Generator TODO List

This document tracks the progress on the development tasks for the Bree-MD project.

## Completed Files/Modules

- [x] `src/config/settings.py` (App configuration & LLM settings)
- [x] `src/config/security.py` (Security settings & API key validation)
- [x] `src/utils/error_handling.py` (Retry logic & Circuit Breaker)
- [x] `src/utils/sanitization.py` (Input sanitization)
- [x] `src/utils/logging.py` (Logging setup)
- [x] `src/core/llm/client.py` (LLM client implementation & LangChain integration)
- [x] `src/core/llm/prompter.py` (Prompt engineering & template definition)

## Remaining TODO Items

### Low-Level Components

#### Code Analysis: File I/O and Codebase Scanning

- [ ] Define input parameters (root directory, ignore patterns)
- [ ] Implement directory listing
- [ ] Implement recursive traversal logic
- [ ] Handle potential file system errors (permissions, broken links)
- [ ] Filter files based on extensions or file patterns to include only source code
- [ ] Exclude irrelevant directories based on a predefined ignore list or .gitignore configuration
- [ ] Store details about each valid file, including path, size, and language
- [ ] Write test for scanning several repositories (Think about implementation with internet, e.g., github, huggingface, gitlab, etc.)

**Agent:** RepoCrawlerAgent  
**Tools:** FileSystemCrawlerTool, GithubRepoDownloaderTool

#### Codebase Understanding: Parsing & Structuring

- [x] Use language-specific parsers to analyze the code structure and extract relevant elements (functions, classes, modules). [Successfully Created for Py, Js, Java, C/C++, JSON.] *(Note: The tools for this still need to be integrated/developed, but the concept is marked as addressed)*
- [ ] Create a Universal Parser using an LLM for extracting and analyzing code structures and other relevant elements

**Agent:** `CodeUnderstandingAgent`

**Tool:** `UniversalCodeParserTool`

- [ ] Arrange the parsed information into a consistent JSON-like format

**Agent:** `CodeUnderstandingAgent`

- [ ] Identify relationships between code files, such as import/export dependencies and cross-module function calls

**Agent:** `CodeUnderstandingAgent`

- [ ] Generate a high-level understanding of the architecture for later prompts

**Agent:** `CodeUnderstandingAgent`

#### Code Preparation for LLM: Formatting and Refining of Code

- [ ] Strip unnecessary whitespace, comments, and inline debug statements *(Sanitization utility exists, but application to code chunks is pending)*
- [ ] Divide large files into logical chunks to fit within the LLM's token limit
- [ ] Add context headers before each chunk to ensure the LLM understands relationships
- [ ] Use vector embeddings to encode code relationships and provide additional context when generating documentation

**Agent:** Potentially `CodeUnderstandingAgent` or `DocumentationGenerationAgent`  
**Tool:** `CodeEmbeddingTool`

### Mid-Level Components

#### Prompt Construction for LLM: Objectives

- [x] Define a custom template that specifies how the LLM should format its output *(Done in `prompter.py`)*
- [x] Use the template to construct a structured prompt for each code chunk *(Done in `prompter.py`)*
- [x] Tweak the prompt and retry if the LLM output does not meet expectations *(Retry mechanism done in `error_handling.py`, "tweak prompt" logic is part of agent/orchestration)*

#### LangChain Integration for LLM Queries

- [x] Use LangChain to connect the LLM API *(Done in client.py)*
- [ ] Break down the workflow into manageable chains: input, processing, and validation

**Agent Design:** Each agent's run method will represent a chain of operations.

- [ ] Send prompts in batches to optimize for API rate limits
- [ ] Ensure parallel processing where possible to reduce latency for large codebases
- [ ] Orchestrator (`main.py`) to manage the flow of data between components

#### Raw Documentation Generation: Objectives

- [ ] Retrieve LLM responses for each prompt *(Handled by client.py, but the agent using it is pending)*

**Agent:** `DocumentationGenerationAgent`  
**Tool:** `LLMTool`

- [ ] Store the raw documentation alongside the corresponding file/chunk metadata

**Agent:** `DocumentationGenerationAgent`

- [ ] Ensure output conforms to the custom documentation template *(Prompting for this is done; verification might be needed)*
- [ ] Post-process the responses to fix formatting issues

#### Usage Examples Integration: Objectives

- [ ] Prompt the LLM to provide realistic examples of how to use functions/classes *(Prompt template done, agent logic pending)*

**Agent:** `UsageExampleGenerationAgent`

**Tool:** `LLMTool`

- [ ] Include variations: basic usage, edge cases, and typical input/output *(Part of prompt engineering/agent logic)*
- [ ] Allow developers to add custom examples via a config file or annotations

**Tool:** Configuration/Annotation Parser Tool

- [ ] Embed examples under dedicated "Usage Example" sections within the generated documentation

**Agent:** `DocumentationAssemblyAgent`

#### Template-Based Assembly: Objectives

- [ ] Combine documentation for individual functions, classes, and modules into cohesive file-level docs

**Agent:** `DocumentationAssemblyAgent`  
**Tool:** `TemplateRendererTool`

- [ ] Organize sections into directories and include navigation

**Agent:** `DocumentationAssemblyAgent`

- [ ] Generate an overview file describing the overall structure and relationships of directories and modules

**Agent:** `DocumentationAssemblyAgent`
